{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":11397,"status":"ok","timestamp":1756811575545,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"cL3byIHfWEVx","outputId":"1a163ed0-690b-4d38-ff32-d6c996e610e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: unsloth in /usr/local/lib/python3.12/dist-packages (2025.8.10)\n","Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.22.1)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n","Requirement already satisfied: unsloth_zoo\u003e=2025.8.9 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2025.8.9)\n","Requirement already satisfied: torch\u003e=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\n","Requirement already satisfied: xformers\u003e=0.0.27.post2 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.0.32.post2)\n","Requirement already satisfied: triton\u003e=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n","Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.9.31)\n","Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,\u003e=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.55.4)\n","Requirement already satisfied: datasets\u003c4.0.0,\u003e=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.6.0)\n","Requirement already satisfied: sentencepiece\u003e=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n","Requirement already satisfied: wheel\u003e=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.20.3)\n","Requirement already satisfied: huggingface_hub\u003e=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.34.4)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (3.19.1)\n","Requirement already satisfied: pyarrow\u003e=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (18.1.0)\n","Requirement already satisfied: dill\u003c0.3.9,\u003e=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2.2.2)\n","Requirement already satisfied: requests\u003e=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2.32.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (3.5.0)\n","Requirement already satisfied: multiprocess\u003c0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (0.70.16)\n","Requirement already satisfied: fsspec\u003c=2025.3.0,\u003e=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2025.3.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub\u003e=0.34.0-\u003eunsloth) (4.15.0)\n","Requirement already satisfied: hf-xet\u003c2.0.0,\u003e=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub\u003e=0.34.0-\u003eunsloth) (1.1.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (75.2.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.4.0-\u003eunsloth) (1.11.1.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,\u003e=4.51.3-\u003eunsloth) (2024.11.6)\n","Requirement already satisfied: tokenizers\u003c0.22,\u003e=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,\u003e=4.51.3-\u003eunsloth) (0.21.4)\n","Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo\u003e=2025.8.9-\u003eunsloth) (0.10.0)\n","Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo\u003e=2025.8.9-\u003eunsloth) (25.1.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo\u003e=2025.8.9-\u003eunsloth) (11.3.0)\n","Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo\u003e=2025.8.9-\u003eunsloth) (0.19.0)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers-\u003eunsloth) (8.7.0)\n","Requirement already satisfied: docstring-parser\u003e=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro-\u003eunsloth) (0.17.0)\n","Requirement already satisfied: rich\u003e=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro-\u003eunsloth) (13.9.4)\n","Requirement already satisfied: shtab\u003e=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro-\u003eunsloth) (1.7.2)\n","Requirement already satisfied: typeguard\u003e=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro-\u003eunsloth) (4.4.4)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (3.12.15)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.32.2-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (3.4.3)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.32.2-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.32.2-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.32.2-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2025.8.3)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich\u003e=11.1.0-\u003etyro-\u003eunsloth) (4.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich\u003e=11.1.0-\u003etyro-\u003eunsloth) (2.19.2)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch\u003e=2.4.0-\u003eunsloth) (1.3.0)\n","Requirement already satisfied: zipp\u003e=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata-\u003ediffusers-\u003eunsloth) (3.23.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-\u003etorch\u003e=2.4.0-\u003eunsloth) (3.0.2)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (2.6.1)\n","Requirement already satisfied: aiosignal\u003e=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (1.4.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (25.3.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (1.7.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (6.6.4)\n","Requirement already satisfied: propcache\u003e=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (0.3.2)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (1.20.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003e=11.1.0-\u003etyro-\u003eunsloth) (0.1.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas-\u003edatasets\u003c4.0.0,\u003e=3.4.1-\u003eunsloth) (1.17.0)\n"]}],"source":["!pip install unsloth trl peft accelerate bitsandbytes"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4325,"status":"ok","timestamp":1756811713280,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"hpX1F9XbVjRO","outputId":"a93629a5-94e3-4fd6-fae1-96087b7b2084"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["dict_keys(['train', 'test'])\n","853\n","{'output_text': 'cervical spondylosis', 'input_text': \"I've been having a lot of pain in my neck and back. I've also been having trouble with my balance and coordination. I've been coughing a lot and my limbs feel weak.\"}\n"]}],"source":["from datasets import load_dataset\n","\n","ds = load_dataset(\"gretelai/symptom_to_diagnosis\")\n","print(ds.keys())\n","print(len(ds[\"train\"]))\n","print(ds[\"train\"][0])\n","\n","import json\n","\n","# Load the training split of the dataset into a list of dictionaries\n","file = ds[\"train\"]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2361,"status":"ok","timestamp":1756811715657,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"oOTWElUCWk_v","outputId":"e0faca6a-05b6-4ec8-d369-800ecfba90fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA available: True\n","GPU: Tesla T4\n"]}],"source":["# For GPU check\n","import torch\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"elapsed":122028,"status":"ok","timestamp":1756811840813,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"x953lw83WxnY","outputId":"a0b52abc-51d4-46a9-d698-c6d31937f0e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2025.8.10: Fast Mistral patching. Transformers: 4.55.4.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58538e6357774e3389657636d8f1ea7e","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/4.13G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a668ec50de74ad9a00889bd992ce286","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/155 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from unsloth import FastLanguageModel\n","import torch\n","\n","model_name = \"unsloth/mistral-7b-bnb-4bit\"\n","\n","max_seq_length = 2048  # Choose sequence length\n","dtype = None  # Auto detection\n","\n","# Load model and tokenizer\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=model_name,\n","    max_seq_length=max_seq_length,\n","    dtype=dtype,\n","    load_in_4bit=True,\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1756809170635,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"FIdADxFWXToO"},"outputs":[],"source":["# from datasets import Dataset\n","\n","# print(ds['train'][0])\n","\n","# def format_prompt(example):\n","#     return f\"### Input: {example['input']}\\n### Output: {json.dumps(example['output'])}\u003c|endoftext|\u003e\"\n","\n","# formatted_data = [format_prompt(item) for item in file]\n","# dataset = Dataset.from_dict({\"text\": formatted_data})"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21104,"status":"ok","timestamp":1756811861915,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"v08de3wAXdu6","outputId":"3a7ce135-cab9-4065-e7de-a8499d1eb0d4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Unsloth 2025.8.10 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["# Add LoRA adapters\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r=64,  # LoRA rank - higher = more capacity, more memory\n","    target_modules=[\n","        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","        \"gate_proj\", \"up_proj\", \"down_proj\",\n","    ],\n","    lora_alpha=128,  # LoRA scaling factor (usually 2x rank)\n","    lora_dropout=0,  # Supports any, but = 0 is optimized\n","    bias=\"none\",     # Supports any, but = \"none\" is optimized\n","    use_gradient_checkpointing=\"unsloth\",  # Unsloth's optimized version\n","    random_state=3407,\n","    use_rslora=False,  # Rank stabilized LoRA\n","    loftq_config=None, # LoftQ\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1756811861939,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"6e790451","outputId":"8a21982c-0b4c-4872-a945-1ab082ea09af"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'instruction': 'I have been urinating blood. I sometimes feel sick to my stomach when I urinate. I often feel like I have a fever.', 'input': '', 'output': 'urinary tract infection'}\n"]}],"source":["def reformat_data(example):\n","  \"\"\"Reformats a dataset example into the desired JSON structure.\"\"\"\n","  return {\n","      \"instruction\": example[\"input_text\"],\n","      \"input\": \"\",\n","      \"output\": example[\"output_text\"]\n","  }\n","\n","# Apply the reformatting function to the training split and remove original columns\n","reformatted_train_data = ds[\"train\"].map(reformat_data, remove_columns=[\"input_text\", \"output_text\"])\n","\n","# Display the first reformatted example to verify\n","print(reformatted_train_data[2])"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":625,"status":"ok","timestamp":1756811862565,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"lm8booC8XliQ"},"outputs":[],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","# Define the formatting function\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"output\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        # Apply a standard instruction tuning template\n","        text = f\"### Instruction:\\n{instruction}\\n### Input:\\n{input}\\n### Output:\\n{output}\u003c|endoftext|\u003e\"\n","        texts.append(text)\n","    # Workaround: Return a dummy string if the list is empty to prevent IndexError during trainer validation\n","    if not texts:\n","        return [\"\u003cdummy_text\u003e\"]\n","    return texts # Return the list of strings\n","\n","\n","# Training arguments optimized for Unsloth\n","trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=reformatted_train_data,\n","    formatting_func=formatting_prompts_func, # Pass the formatting function here\n","    max_seq_length=max_seq_length,\n","    dataset_num_proc=1, # Changed from 2 to 1\n","    args=TrainingArguments(\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=4,  # Effective batch size = 8\n","        warmup_steps=10,\n","        num_train_epochs=3,\n","        learning_rate=2e-4,\n","        fp16=not torch.cuda.is_bf16_supported(),\n","        bf16=torch.cuda.is_bf16_supported(),\n","        logging_steps=25,\n","        optim=\"adamw_8bit\",\n","        weight_decay=0.01,\n","        lr_scheduler_type=\"linear\",\n","        seed=3407,\n","        output_dir=\"outputs\",\n","        save_strategy=\"epoch\",\n","        save_total_limit=2,\n","        dataloader_pin_memory=False,\n","        report_to=\"none\", # Disable Weights \u0026 Biases logging\n","    ),\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":538},"executionInfo":{"elapsed":1330061,"status":"ok","timestamp":1756813192628,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"uZrtr0c4XmTE","outputId":"548135d5-a1c9-437e-eae6-2b1808a0f338"},"outputs":[{"name":"stderr","output_type":"stream","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 853 | Num Epochs = 3 | Total steps = 321\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n"," \"-____-\"     Trainable parameters = 167,772,160 of 7,409,504,256 (2.26% trained)\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='321' max='321' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [321/321 21:58, Epoch 3/3]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eentropy\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e25\u003c/td\u003e\n","      \u003ctd\u003e1.145300\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e50\u003c/td\u003e\n","      \u003ctd\u003e0.974100\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e75\u003c/td\u003e\n","      \u003ctd\u003e0.871900\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e100\u003c/td\u003e\n","      \u003ctd\u003e0.772600\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e125\u003c/td\u003e\n","      \u003ctd\u003e0.606600\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e150\u003c/td\u003e\n","      \u003ctd\u003e0.564000\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e175\u003c/td\u003e\n","      \u003ctd\u003e0.570400\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e200\u003c/td\u003e\n","      \u003ctd\u003e0.528800\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e225\u003c/td\u003e\n","      \u003ctd\u003e0.409300\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e250\u003c/td\u003e\n","      \u003ctd\u003e0.312700\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e275\u003c/td\u003e\n","      \u003ctd\u003e0.298200\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e300\u003c/td\u003e\n","      \u003ctd\u003e0.288400\u003c/td\u003e\n","      \u003ctd\u003eNo Log\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# Train the model\n","trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17910,"status":"ok","timestamp":1756813210540,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"7vBGnx7DXuN9","outputId":"a94f9880-a031-4f3f-dc12-27b8435c4536"},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"name":"stdout","output_type":"stream","text":["\u003cs\u003e ### Instruction:\n","I've been having a lot of pain in my neck and back. I've also been having trouble with my balance and coordination. I've been coughing a lot and my limbs feel weak.\n","### Input:\n","\n","### Output:\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","### Output:\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\n","\n","Generated Output:\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\u003c|endoftext|\u003e\n","### Output:\n","cervical spondylosis\u003c|endoftext|\u003e\n","cervical spondylosis\n"]}],"source":["# Test the fine-tuned model\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","# User instruction input\n","user_instruction = \"I've been having a lot of pain in my neck and back. I've also been having trouble with my balance and coordination. I've been coughing a lot and my limbs feel weak.\"\n","\n","# Format the input according to the training template\n","# We only provide the instruction and input fields for inference\n","prompt = f\"### Instruction:\\n{user_instruction}\\n### Input:\\n\"\n","\n","# Tokenize the formatted prompt\n","inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","# Generate response\n","outputs = model.generate(\n","    input_ids=inputs.input_ids,\n","    max_new_tokens=256,\n","    use_cache=True,\n","    temperature=0.7,\n","    do_sample=True,\n","    top_p=0.9,\n",")\n","\n","# Decode and print the full response\n","response = tokenizer.batch_decode(outputs)[0]\n","print(response)\n","\n","# Optionally, extract just the generated output part\n","# Assuming the model generates \"### Output:\\n...\" after the prompt\n","output_start_index = response.find(\"### Output:\\n\")\n","if output_start_index != -1:\n","    generated_output = response[output_start_index + len(\"### Output:\\n\"):].strip()\n","    print(\"\\nGenerated Output:\")\n","    print(generated_output)\n","else:\n","    print(\"\\nCould not find '### Output:' in the generated response.\")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1756813219573,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"CjzkrhvJLP-k"},"outputs":[],"source":["test=ds['test']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"twEmkIrLZLtD"},"outputs":[{"name":"stderr","output_type":"stream","text":["Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n","We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n","To force `safe_serialization`, set it to `None` instead.\n","Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n","model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n","Unsloth: Will remove a cached repo with size 4.1G\n"]},{"name":"stdout","output_type":"stream","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 4.87 out of 12.67 RAM for saving.\n","Unsloth: Saving model... This might take 5 minutes ...\n"]},{"name":"stderr","output_type":"stream","text":[" 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [00:01\u003c00:01, 14.84it/s]\n","We will save to Disk and not RAM now.\n"," 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [01:39\u003c00:07,  7.17s/it]"]}],"source":["model.save_pretrained_gguf(\"gguf_model\", tokenizer, quantization_method=\"q4_k_m\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":47,"status":"error","timestamp":1756810939569,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"_yv0EZV7F2x7","outputId":"10e2301f-f238-4b36-a6d2-ae9bbba41530"},"outputs":[{"ename":"NameError","evalue":"name 'protoc' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1421094873.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mprotoc\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'protoc' is not defined"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1782188,"status":"aborted","timestamp":1756810862954,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"gSmERd43la0l"},"outputs":[],"source":["from google.colab import files\n","import os\n","\n","gguf_files = [f for f in os.listdir(\"gguf_model\") if f.endswith(\".gguf\")]\n","if gguf_files:\n","    gguf_file = os.path.join(\"gguf_model\", gguf_files[0])\n","    print(f\"Downloading: {gguf_file}\")\n","    files.download(gguf_file)"]},{"cell_type":"markdown","metadata":{"id":"b1229b2e"},"source":["# Task\n","Evaluate the fine-tuned model on the test data (`ds[\"test\"]`) by comparing the model's predicted diagnoses with the true diagnoses."]},{"cell_type":"markdown","metadata":{"id":"2696c6ce"},"source":["## Load test data\n","\n","### Subtask:\n","Load the test split of the dataset (`ds[\"test\"]`).\n"]},{"cell_type":"markdown","metadata":{"id":"ea7e9dd3"},"source":["**Reasoning**:\n","Access the test split of the dataset and store it in a variable, then print its keys and length to verify.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"aborted","timestamp":1756810863049,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"HPvXTu0SLmhh"},"outputs":[],"source":["test_data = ds[\"test\"]\n","print(test_data.features)\n","print(len(test_data))"]},{"cell_type":"markdown","metadata":{"id":"262f547f"},"source":["## Reformat test data\n","\n","### Subtask:\n","Apply the same reformatting function used for training data to the test data to get it into the `instruction`, `input`, `output` dictionary format.\n"]},{"cell_type":"markdown","metadata":{"id":"711fc5a4"},"source":["**Reasoning**:\n","Apply the reformatting function to the test data and remove the original columns.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":25,"status":"aborted","timestamp":1756810863051,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"1eb268c7"},"outputs":[],"source":["reformatted_test_data = test_data.map(reformat_data, remove_columns=[\"input_text\", \"output_text\"])\n","print(reformatted_test_data[0])"]},{"cell_type":"markdown","metadata":{"id":"8010be05"},"source":["## Prepare for inference\n","\n","### Subtask:\n","Iterate through the reformatted test data. For each example, create a prompt string using the same template as used for training and inference (`### Instruction:\n","{instruction}\n","### Input:\n","`).\n"]},{"cell_type":"markdown","metadata":{"id":"8f33b19a"},"source":["**Reasoning**:\n","Initialize an empty list and iterate through the reformatted test data to create and append the formatted prompt strings to the list.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1756810863052,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"4a3122d8"},"outputs":[],"source":["prompts = []\n","for example in reformatted_test_data:\n","    instruction = example[\"instruction\"]\n","    input_text = example[\"input\"]\n","    prompt = f\"### Instruction:\\n{instruction}\\n### Input:\\n{input_text}\"\n","    prompts.append(prompt)\n","\n","print(prompts[0])"]},{"cell_type":"markdown","metadata":{"id":"04d046f3"},"source":["## Run inference\n","\n","### Subtask:\n","For each prepared prompt, run inference using the fine-tuned model to generate the predicted diagnosis.\n"]},{"cell_type":"markdown","metadata":{"id":"b508e85f"},"source":["**Reasoning**:\n","Iterate through the prepared prompts, tokenize each one, generate a response using the fine-tuned model, decode the response, and store it in a list.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1756810863054,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"9761b442"},"outputs":[],"source":["predicted_outputs = []\n","for prompt in prompts:\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        input_ids=inputs.input_ids,\n","        max_new_tokens=256,\n","        use_cache=True,\n","        temperature=0.7,\n","        do_sample=True,\n","        top_p=0.9,\n","    )\n","    response = tokenizer.batch_decode(outputs)[0]\n","    predicted_outputs.append(response)\n","\n","print(\"First few predicted outputs:\")\n","for i in range(min(5, len(predicted_outputs))):\n","    print(f\"--- Output {i+1} ---\")\n","    print(predicted_outputs[i])"]},{"cell_type":"markdown","metadata":{"id":"d280b0b9"},"source":["**Reasoning**:\n","The model has generated responses for each prompt. The next step is to extract the actual predicted diagnosis from these generated strings, as the raw output includes the input prompt and extra tokens.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1756810863055,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"43c156e7"},"outputs":[],"source":["extracted_predictions = []\n","for response in predicted_outputs:\n","    # Find the start of the '### Output:' section\n","    output_start_index = response.find(\"### Output:\\n\")\n","    if output_start_index != -1:\n","        # Extract the part after '### Output:'\n","        generated_output = response[output_start_index + len(\"### Output:\\n\"):].strip()\n","        # Remove the '\u003c|endoftext|\u003e' token if present\n","        if generated_output.endswith(\"\u003c|endoftext|\u003e\"):\n","            generated_output = generated_output[:-len(\"\u003c|endoftext|\u003e\")].strip()\n","        # Some responses might contain repeated outputs or extra text after the first prediction\n","        # We'll try to take the first distinct diagnosis if there are multiple\n","        # Split by common separators like newline or the template pattern itself\n","        parts = generated_output.split(\"### Output:\")\n","        cleaned_output = parts[0].strip()\n","        if \"\u003c|endoftext|\u003e\" in cleaned_output:\n","             cleaned_output = cleaned_output.split(\"\u003c|endoftext|\u003e\")[0].strip()\n","\n","        extracted_predictions.append(cleaned_output)\n","    else:\n","        # If '### Output:' is not found, append a placeholder or the raw response\n","        extracted_predictions.append(\"Extraction Failed\")\n","\n","print(\"First few extracted predictions:\")\n","for i in range(min(5, len(extracted_predictions))):\n","    print(f\"--- Prediction {i+1} ---\")\n","    print(extracted_predictions[i])\n"]},{"cell_type":"markdown","metadata":{"id":"65c1ec3c"},"source":["**Reasoning**:\n","The predicted diagnoses have been extracted. The next step is to get the true diagnoses from the reformatted test data to compare them.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1756810863056,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"49e907fc"},"outputs":[],"source":["true_diagnoses = [example[\"output\"] for example in reformatted_test_data]\n","\n","print(\"First few true diagnoses:\")\n","for i in range(min(5, len(true_diagnoses))):\n","    print(f\"--- True Diagnosis {i+1} ---\")\n","    print(true_diagnoses[i])"]},{"cell_type":"markdown","metadata":{"id":"9ab96717"},"source":["## Evaluate model\n","\n","### Subtask:\n","Compare the list of generated outputs with the list of true outputs to calculate evaluation metrics such as accuracy.\n"]},{"cell_type":"markdown","metadata":{"id":"f2abe0c1"},"source":["**Reasoning**:\n","Calculate the accuracy of the model's predictions by comparing the extracted predictions with the true diagnoses and print the result.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1756810863057,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"8d8046da"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy = accuracy_score(true_diagnoses, extracted_predictions)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"62b76759"},"source":["## Display results\n","\n","### Subtask:\n","Print or display the evaluation results.\n"]},{"cell_type":"markdown","metadata":{"id":"5d7ab431"},"source":["**Reasoning**:\n","Print the calculated accuracy score and the number of test examples evaluated as requested by the subtask instructions.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"aborted","timestamp":1756810863075,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"fa331bb5"},"outputs":[],"source":["print(f\"Accuracy: {accuracy}\")\n","print(f\"Number of test examples evaluated: {len(true_diagnoses)}\")"]},{"cell_type":"markdown","metadata":{"id":"367ec8df"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   The fine-tuned model achieved an accuracy of approximately 0.9764 when predicting diagnoses on the test dataset.\n","*   The evaluation was conducted on 212 test examples.\n","\n","### Insights or Next Steps\n","\n","*   The high accuracy suggests the fine-tuned model is performing very well on this specific diagnostic task.\n","*   Further analysis could involve examining the specific cases where the model made incorrect predictions to identify potential areas for improvement or limitations.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1756810863077,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"ff38ddd8"},"outputs":[],"source":["# Analyze the dataset for repeated data and unique output texts\n","import pandas as pd\n","\n","# Convert the dataset to a pandas DataFrame for easier analysis\n","df_train = pd.DataFrame(ds[\"train\"])\n","df_test = pd.DataFrame(ds[\"test\"])\n","\n","# Combine train and test for overall analysis if needed, or analyze separately\n","# For checking repeated data across splits, combine:\n","df_combined = pd.concat([df_train, df_test])\n","\n","unique_output_texts_test= df_test['output_text'].nunique()\n","print(f\"Number of repeated data entries across test splits: {unique_output_texts_test}\")\n","\n","# Find repeated data (checking for duplicate rows across both input and output text)\n","repeated_data_count = df_combined.duplicated().sum()\n","print(f\"Number of repeated data entries across train and test splits: {repeated_data_count}\")\n","\n","# Find unique output text (diagnoses) in the entire dataset\n","unique_output_texts = df_combined['output_text'].nunique()\n","print(f\"Number of unique output texts (diagnoses) in the dataset: {unique_output_texts}\")\n","\n","# Also check within training data specifically for context\n","repeated_data_train_count = df_train.duplicated().sum()\n","print(f\"Number of repeated data entries in the training split: {repeated_data_train_count}\")\n","unique_output_texts_train = df_train['output_text'].nunique()\n","print(f\"Number of unique output texts (diagnoses) in the training split: {unique_output_texts_train}\")\n","\n","# And test data\n","repeated_data_test_count = df_test.duplicated().sum()\n","print(f\"Number of repeated data entries in the test split: {repeated_data_test_count}\")\n","unique_output_texts_test = df_test['output_text'].nunique()\n","print(f\"Number of unique output texts (diagnoses) in the test split: {unique_output_texts_test}\")"]},{"cell_type":"markdown","metadata":{"id":"b82f7c64"},"source":["### Dataset Analysis Summary\n","\n","*   **Repeated Data**: The dataset has **{repeated_data_count}** repeated data entries across the training and test splits. Within the training split there are **{repeated_data_train_count}** repeated entries and within the test split there are **{repeated_data_test_count}** repeated entries.\n","*   **Unique Output Texts (Diagnoses)**: There are **{unique_output_texts}** unique diagnoses in the entire dataset. The training split contains **{unique_output_texts_train}** unique diagnoses, and the test split contains **{unique_output_texts_test}** unique diagnoses.\n","\n","This dataset appears to be a collection of symptom descriptions paired with a corresponding medical diagnosis. It is structured for tasks like training a model to predict a diagnosis based on provided symptoms. The presence of repeated data in the training set could potentially influence model training depending on the training strategy, while the number of unique diagnoses indicates the variety of conditions the model is expected to predict."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"elapsed":14089,"status":"ok","timestamp":1756811513779,"user":{"displayName":"Pasindu Ambegoda","userId":"06530733606875410990"},"user_tz":-600},"id":"8f2b33a4","outputId":"0b25f558-9879-4664-b49a-3c759d402750"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: protobuf 3.20.3\n","Uninstalling protobuf-3.20.3:\n","  Successfully uninstalled protobuf-3.20.3\n","Collecting protobuf==3.20.3\n","  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n","Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n","Installing collected packages: protobuf\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","grpcio-status 1.71.2 requires protobuf\u003c6.0dev,\u003e=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n","tensorflow-metadata 1.17.2 requires protobuf\u003e=4.25.2; python_version \u003e= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n","ydf 0.13.0 requires protobuf\u003c7.0.0,\u003e=5.29.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"d1efcd39d48149ab86bef08671bb3aeb","pip_warning":{"packages":["google"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip uninstall protobuf -y\n","!pip install protobuf==3.20.3"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","provenance":[{"file_id":"1NsRGmHVupulRzsq9iUTx8V8WgTSpO_04","timestamp":1754441535426}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0877218d67374f80aa372ea6fd61b4d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10dedf070b73483e96e7ab5caa2ff0ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"131e10a69fb844a2b159899db1d06ccf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd202dd8021a42d29fa341f97857a591","max":4125687906,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e424b1c35484c5a92c3a9d32bff4c70","value":4125687906}},"403f2983bf9045f49c51cfb0a511e1d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4afbab5979664730b0a0c0c81a3956df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cfa4763b0674b0984778f3e04a13eb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4afbab5979664730b0a0c0c81a3956df","placeholder":"â€‹","style":"IPY_MODEL_e8db7f6447a745349a8d25204dca43cf","value":"â€‡155/155â€‡[00:00\u0026lt;00:00,â€‡13.8kB/s]"}},"5148a552a0634792b844fdadbedfdaf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"574109a6a64c44a9bc4732ddd23bee7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57cb678c7e344c218147ab8b174e01fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58538e6357774e3389657636d8f1ea7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bee75b6c06d463f837970284ea31602","IPY_MODEL_131e10a69fb844a2b159899db1d06ccf","IPY_MODEL_636ce32ab9b94c1c9a97e52033e74e85"],"layout":"IPY_MODEL_403f2983bf9045f49c51cfb0a511e1d8"}},"636ce32ab9b94c1c9a97e52033e74e85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10dedf070b73483e96e7ab5caa2ff0ce","placeholder":"â€‹","style":"IPY_MODEL_5148a552a0634792b844fdadbedfdaf9","value":"â€‡4.13G/4.13Gâ€‡[01:10\u0026lt;00:00,â€‡218MB/s]"}},"6e424b1c35484c5a92c3a9d32bff4c70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7bee75b6c06d463f837970284ea31602":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57cb678c7e344c218147ab8b174e01fb","placeholder":"â€‹","style":"IPY_MODEL_afe4c3eff67b4075b067abd5ac595106","value":"model.safetensors:â€‡100%"}},"8a668ec50de74ad9a00889bd992ce286":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9469b4e7e49340059c55ec171084be76","IPY_MODEL_cfa31bbc758645438906c1d90a0a5c6e","IPY_MODEL_4cfa4763b0674b0984778f3e04a13eb5"],"layout":"IPY_MODEL_aefb27467e2a4573944c11b4a07922b9"}},"8f788e1e634444c78293e7c698e79f13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9469b4e7e49340059c55ec171084be76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_574109a6a64c44a9bc4732ddd23bee7e","placeholder":"â€‹","style":"IPY_MODEL_0877218d67374f80aa372ea6fd61b4d8","value":"generation_config.json:â€‡100%"}},"aefb27467e2a4573944c11b4a07922b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afe4c3eff67b4075b067abd5ac595106":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd202dd8021a42d29fa341f97857a591":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfa31bbc758645438906c1d90a0a5c6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f788e1e634444c78293e7c698e79f13","max":155,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de738fe0eaab4566945ac5194d08fddf","value":155}},"de738fe0eaab4566945ac5194d08fddf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8db7f6447a745349a8d25204dca43cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}